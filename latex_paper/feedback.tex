\chapter{Nutzerevaluation und Feedback}
\section{Nutzerumfrage}
Um uns ein Bild von der Akzeptanz unseres Chatbots bei Nutzern zu machen und auf welche Art und Weisen diese interagieren, haben wir eine Umfrage unter\\\texttt{https://forms.gle/1doFP9G4LbG83cuH9} erstellt, die auch im Chatbot unter der Eingabe "/feedback" zu erreichen war. Dort sind nach wie vor alle Fragen nachlesbar.\\

\subsection{Quantitative Auswertung}
Auf die Frage, wie viele ungefähr der Nutzereingaben eine erfolgreiche Reaktion erzeugten, antworteten die Nutzer im Mittel mit $58.34\%$. Das sind in der subjektiven Wahrnehmung der Nutzer, mehr als die Hälfte aller Anfragen.\\

Da wir uns des Problems, das JANUS gelegentlich Adress- mit Zeitangaben verwechselt, im Vorhinein bewusst waren, fragten wir, ob dies bei der Testnutzung mindestens einmal der Fall war. Dies bestätigten zwei Drittel der Nutzer. In einem von drei Konversationen, ist dieser Fehler also gar nicht erst aufgetreten.\\
Darauf aufbauend erfragten wir, ob dies ein Ausschlußkriterium für einen zukünftigen Gebrauch wäre. Zwei Drittel der Nutzer waren uns positiv gestimmt, und sahen dies nicht als ein zu großes Problem an.

\subsection{Qualitative Auswertung}
Wir baten unsere Nutzer, folgende Fragen auf ihre Zustimmung oder Ablehnung hin zu überprüfen:\\

\textit{"Die Fragen und Äußerungen des Bots waren jeder Zeit verständlich und ich wusste, was ich zu tun habe."}\\
Der überwiegende Teil der Nutzer, mit einem Anteil von $2/3$, stimmten dieser Aussage zu, wobei allerdings auch ein Drittel dieser Aussage nicht zustimmten.\\

\textit{"Ich wusste jeder Zeit, was ich als nächstes tun konnte."}\\
Dem stimmten über $80\%$ der Befragten zu, was im Großen als eine ausreichende Führung der Nutzer, durch die Konversationen, verstanden werden kann.\\

\textit{Ich wusste jeder Zeit, welche Fragen ich dem Chatbot stellen konnte.}\\
Hier gingen die Meinungen der Nutzer teils stark auseinander. Die Hälfte der Nutzer stimmten dem nicht zu und die andere Hälfte verteilte sich auf eine zustimmende und neutrale Antwortmöglichkeit.


\textit{"Im Falle, dass der Bot nicht verstanden hat, was ich sagte, waren seine Antworten trotzdem sehr verständlich."}\\
Auch war keine zu große Einigkeit erkennbar. Immerhin die Hälfte aller Befragten antworteten zustimmend. Die andere Hälfte verteilt sich erneut auf eine neutrale und ablehnende Antwort.\\

Für die folgenden Fragen baten wir die Nutzer, ihre Antwort auf einer Skala von 1 (ablehnend, schlecht) bis 10 (zustimmend, sehr gut) zu bewerten.\\

\textit{"Hat Dir das Chatten mit JANUS Spaß gemacht?"}
Die durchschnittliche Bewertung lag hier bei über $7.66$ Punkten, was wir als deutlichen Zuspruch für unseren Chatbot werten.\\

\textit{"Sind die generierten Pläne für Deine Zeitplanung hilfreich?"}\\
Der Durchscnitt lag hier bei $6.34$ Punkten. Dies zeigt uns, dass wir an der Aussagekraft der generierten Darstellung zu arbeiten haben.\\

\textit{"Wie visuell ansprechend findest Du die generierten Pläne?"}\\
Mit einer durchschnittlichen Punktzahl von $7.67$ Punkten sehen wir uns bestätigt, dass die Pläne nicht aufgrund des Designs weniger hilfreich sind, sondern aufgrund eines Mangels an Informationen.\\

\textit{"Würdest Du in Erwägung ziehen, JANUS auch zukünftig für Deine Zeitplanung zu verwenden?"}\\
Hier liegt die durchschnittliche Punktzahl bei fast $5.84$. Dies ist natürlich kein wünscheswertes Ergebnis, welches wir auf die vielen kleinen Fehler in der NLP zurückführen. Es ist auch denkbar, dass sich ein Chatbot für das Planen von Terminen im Allgemeinen nicht auf große Akzeptanz stützt. 

\subsection{Auswertung der Interpretationsfähigkeit}
Nun haben wir erfragt, welches die häufigsten Sätze waren, die JANUS nicht verstehen konnte. Neben dem von uns antizipiertem Fehler, dass Zeit- und Ortsangaben verwechselt werden, überraschten uns die Nutzer bswp. mit Eigennamen als Adressangabe, sowie einer zu schlechten Erkennung von Uhrzeit und Datum.\\
Da abgesehen von diesen Fehlern keine weiteren genannt wurden, gehen wir von einem insgesamt robustem System aus. Tatsächlich stürzte der Bot zu keinem Zeitpunkt in der Testphase ab.\\

Interessanter Weise, sagten die Nutzer nahezu geschlossen aus, dass sie von den Antworten des Bots nicht überrascht waren und großteils ihren Erwartungen entsprochen haben.
